{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "%matplotlib inline\n",
                "from IPython.display import clear_output\n",
                "import time\n",
                "from Environments.environments import all_envs, get_all_avail_envs\n",
                "from Agents.dqn_agent import DQN_Agent\n",
                "from Agents.ppo_agent import PPO_Agent\n",
                "from Models import fc, rnn\n",
                "import matplotlib.pyplot as plt\n",
                "import torch\n",
                "import utils\n",
                "from Curriculum_managers.random_curriculum import Random_Curriculum\n",
                "import plotly.express as px\n",
                "import gym\n",
                "import os\n",
                "# os.environ[\"LANG\"]=\"en_US\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['SingleTaxiEnv',\n",
                            " 'FrozenLakeEnv',\n",
                            " 'AdversarialEnv',\n",
                            " 'ReparameterizedAdversarialEnv',\n",
                            " 'MiniAdversarialEnv',\n",
                            " 'MiniReparameterizedAdversarialEnv',\n",
                            " 'NoisyAdversarialEnv',\n",
                            " 'MediumAdversarialEnv',\n",
                            " 'GoalLastAdversarialEnv',\n",
                            " 'MiniGoalLastAdversarialEnv']"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "env_names = get_all_avail_envs()\n",
                "env_names"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "device = utils.init_torch()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "env = all_envs['SingleTaxiEnv'](random_reset_loc=True)\n",
                "n_actions = env.action_space.n\n",
                "obs_shape = env.observation_space['image'].shape\n",
                "env.dummy_init()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "# env = gym.envs.make(\"CartPole-v1\")\n",
                "# n_actions = env.action_space.n\n",
                "# obs_shape = env.observation_space.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Agent train single env example:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "agent = DQN_Agent(obs_shape, n_actions, device=device, batch_size=64, max_mem_size=10**5, exploration_epsilon=0.3, eps_dec=0, lr=0.001)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "R:-00604.5:   2%|‚ñè         | 98/5000 [03:49<3:08:01,  2.30s/it]"
                    ]
                }
            ],
            "source": [
                "r_teacher = Random_Curriculum(env, trainee=agent)\n",
                "train_r = r_teacher.teach(n_iters=5000, n_episodes=8)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "e = r_teacher.create_env()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+---------+\n",
                        "|\u001b[35mG\u001b[0m| : : |\u001b[43m \u001b[0m|\n",
                        "| : : : : |\n",
                        "| : : : : |\n",
                        "| : :\u001b[34;1mY\u001b[0m| |F|\n",
                        "| : : : : |\n",
                        "+---------+\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "e.render()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [
                {
                    "ename": "TypeError",
                    "evalue": "object of type 'numpy.int64' has no len()",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m/tmp/ipykernel_98436/1621136671.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train rewards'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.int64' has no len()"
                    ]
                }
            ],
            "source": [
                "fig = px.line(x=range(len(train_r)), y=train_r, title='Train rewards')\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "agent.set_eval_mode()\n",
                "for i in range(1):\n",
                "    obs = e.reset()\n",
                "    # break\n",
                "    R = 0\n",
                "    t = 0\n",
                "    while True:\n",
                "        # Uncomment to watch the behavior in a GUI window\n",
                "        clear_output(wait=True)\n",
                "        plt.imshow(e.render('rgb_array'))\n",
                "        plt.show()\n",
                "        # env.render(mode='rgb_array')\n",
                "        # env.render()\n",
                "        action = agent.act(obs)\n",
                "        obs, r, done, _ = e.step(action)\n",
                "        print(action, r, done)\n",
                "\n",
                "        R += r\n",
                "        t += 1\n",
                "        reset = t == 500\n",
                "        time.sleep(0.5)\n",
                "        if done or reset:\n",
                "            break\n",
                "    print('evaluation episode:', i, 'R:', R)"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "6939f772228930f094315145e416d5954b20b1f6473e0de1ef78293fcab749f1"
        },
        "kernelspec": {
            "display_name": "Python 3.9.7 64-bit ('venv': venv)",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.9"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
