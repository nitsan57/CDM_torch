{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "%matplotlib inline\n",
                "from IPython.display import clear_output\n",
                "import time\n",
                "from Environments.environments import train_envs, get_all_avail_envs, get_all_avail_test_envs, test_envs\n",
                "from Agents.dqn_agent import DQN_Agent\n",
                "from Agents.ppo_agent import PPO_Agent\n",
                "from Models import fc, rnn\n",
                "import matplotlib.pyplot as plt\n",
                "import utils\n",
                "from Curriculum_managers.random_curriculum import Random_Curriculum\n",
                "from Curriculum_managers.paired_curriculum import PAIRED_Curriculum\n",
                "from Curriculum_managers.paired_curriculum_or import PAIRED_Curriculum_OR\n",
                "# from Curriculum_managers.paired_curriculum_hf import PAIRED_Curriculum_History_filter\n",
                "# from Curriculum_managers.paired_curriculum_hfe import PAIRED_Curriculum_History_filter_Entropy\n",
                "from Curriculum_managers.repaired_curriculum import REPAIRED_Curriculum\n",
                "from Curriculum_managers.climb import CLIMB\n",
                "from Curriculum_managers.curriculum_no_regulator_he import Curriculum_Unregulated_Entropy_History\n",
                "\n",
                "import plotly.express as px\n",
                "import numpy as np\n",
                "import plotly.io as pio\n",
                "import cv2\n",
                "pio.renderers.default = \"browser\"\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_res(vec, title):\n",
                "    fig = px.line(x=range(len(np.convolve(vec, np.ones(100)/100,mode='valid'))), y=np.convolve(vec, np.ones(100)/100, mode='valid'), title=title)\n",
                "    fig.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "['SingleTaxiEnv', 'FrozenLakeEnv', 'AdversarialEnv', 'ReparameterizedAdversarialEnv', 'MiniAdversarialEnv', 'MiniReparameterizedAdversarialEnv', 'NoisyAdversarialEnv', 'MediumAdversarialEnv', 'GoalLastAdversarialEnv', 'MiniGoalLastAdversarialEnv', 'Sokoban']\n"
                    ]
                }
            ],
            "source": [
                "device = utils.init_torch()\n",
                "env_names = get_all_avail_envs()\n",
                "print(env_names[:15])\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "define n_iters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "n_iters = 50000"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "env = train_envs['FrozenLakeEnv'](n_clutter=10)\n",
                "n_actions = env.get_action_space().n\n",
                "obs_shape = env.get_observation_space()\n",
                "gen_obs_shape = env.get_generator_observation_space()\n",
                "gen_action_dim = env.get_generator_action_space().n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "env.init_from_vec([10,1,2,3,4,5,6,7,8,9, 10])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<matplotlib.image.AxesImage at 0x7f312e7e6280>"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "plt.imshow(env.render('rgb_array'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<matplotlib.image.AxesImage at 0x7f312e71b730>"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "env.step(0)\n",
                "plt.imshow(env.render('rgb_array'))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# RANDOM CURRICULUM"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "r_agent = PPO_Agent(obs_shape, n_actions, device=device, batch_size=64, max_mem_size=10**5,num_parallel_envs=4, lr=0.0001, model=rnn.RNN)\n",
                "r_teacher = Random_Curriculum(env ,trainee=r_agent)\n",
                "r_rewards = r_teacher.teach(n_iters=n_iters, n_episodes=1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# PAIRED CURRICULUM"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "p_agent = PPO_Agent(obs_shape, n_actions, device=device, batch_size=64, max_mem_size=10**5, lr=0.0001, model=rnn.RNN)\n",
                "teacher_agent = PPO_Agent(gen_obs_shape, gen_action_dim, device=device, batch_size=64, max_mem_size=10**5, lr=0.0001, model=rnn.RNN)\n",
                "p_teacher = PAIRED_Curriculum(env, teacher_agent=teacher_agent ,trainee=p_agent)\n",
                "p_rewards = p_teacher.teach(n_iters=200, n_episodes=1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# PAIRED CURRICULUM OR"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "no files to load from\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "R:000000.0, entropy: 1.386: 100%|██████████| 200/200 [00:33<00:00,  6.01it/s]\n"
                    ]
                }
            ],
            "source": [
                "por_agent = PPO_Agent(obs_shape, n_actions, device=device, batch_size=64, max_mem_size=10**5, lr=0.0001, model=rnn.RNN)\n",
                "por_teacher_agent = PPO_Agent(gen_obs_shape, gen_action_dim, device=device, batch_size=64, max_mem_size=10**5, lr=0.0001, model=rnn.RNN)\n",
                "por_teacher = PAIRED_Curriculum_OR(env, teacher_agent=por_teacher_agent ,trainee=por_agent)\n",
                "por_rewards = por_teacher.teach(n_iters=200, n_episodes=1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# REPAIRED"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "no files to load from\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/50000 [00:00<?, ?it/s]\n"
                    ]
                },
                {
                    "ename": "IndexError",
                    "evalue": "list index out of range",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
                        "\u001b[0;32m/tmp/ipykernel_540145/1945766740.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mphf_teacher_agent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPPO_Agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_obs_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_action_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_mem_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mphf_teacher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mREPAIRED_Curriculum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mphf_teacher_agent\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtrainee\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mphf_agent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mphf_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphf_teacher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;32m~/Documents/Study/CDM_torch_pddl/Curriculum_managers/repaired_curriculum.py\u001b[0m in \u001b[0;36mteach\u001b[0;34m(self, n_iters, n_episodes)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mload_from_mem\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                 \u001b[0mtrainee_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_episodial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_episodes\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnumber_episodes_for_regret_calc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#train n_episodes per generated_env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m                 \u001b[0mantagonist_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantagonist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_episodial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_episodes\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnumber_episodes_for_regret_calc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#train n_episodes per generated_env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0mtrainee_max_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainee_rewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/Documents/Study/CDM_torch_pddl/Agents/drl_agent.py\u001b[0m in \u001b[0;36mtrain_episodial\u001b[0;34m(self, env, n_episodes, max_episode_len, disable_tqdm, additional_const_features)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_episodes\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_parallel_envs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_num_parallel_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mtrain_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_n_iters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_episodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_episode_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_episode_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_const_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madditional_const_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_r\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/Documents/Study/CDM_torch_pddl/Agents/drl_agent.py\u001b[0m in \u001b[0;36m_train_n_iters\u001b[0;34m(self, env, n_iters, episodes, max_episode_len, disable_tqdm, additional_const_features)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mep_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_iters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0mrewards_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_episode_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_episode_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_to_collect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_parallel_envs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_const_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madditional_const_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0mnum_steps_collected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrewards_vector\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/Documents/Study/CDM_torch_pddl/Agents/drl_agent.py\u001b[0m in \u001b[0;36mcollect_episode_obs\u001b[0;34m(self, env, max_episode_len, num_to_collect, env_funcs, additional_const_features)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_dones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0mrelevant_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_dones\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mcurrent_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatest_observations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_parallel_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0;31m# TODO DEBUG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0;31m# allways use all envs to step, even some envs are done already\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/Documents/Study/CDM_torch_pddl/Agents/ppo_agent.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, observations, num_obs)\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_values\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_parallel_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstored_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m                 \u001b[0mselected_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mIndexError\u001b[0m: list index out of range"
                    ]
                }
            ],
            "source": [
                "phf_agent = PPO_Agent(obs_shape, n_actions, device=device, batch_size=64, max_mem_size=10**5, lr=0.0001, model=rnn.RNN)\n",
                "phf_teacher_agent = PPO_Agent(gen_obs_shape, gen_action_dim, device=device, batch_size=64, max_mem_size=10**5, lr=0.0001, model=rnn.RNN)\n",
                "phf_teacher = REPAIRED_Curriculum(env, teacher_agent=phf_teacher_agent ,trainee=phf_agent)\n",
                "phf_rewards = phf_teacher.teach(n_iters=n_iters, n_episodes=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "phf_teacher.set_agents_to_train_mode()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "phf_teacher.trainee.store_values"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/50000 [00:00<?, ?it/s]\n"
                    ]
                },
                {
                    "ename": "TypeError",
                    "evalue": "'type' object is not iterable",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m/tmp/ipykernel_529177/1557513426.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mphf_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphf_teacher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;32m~/Documents/Study/CDM_torch_pddl/Curriculum_managers/repaired_curriculum.py\u001b[0m in \u001b[0;36mteach\u001b[0;34m(self, n_iters, n_episodes)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mload_from_mem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;31m# follow replay-decision Bernoulli with d=0.5, algorithm as explained in the paper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# if generated new env - envs[0] == envs[1] Trainee, Antagonist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0menvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_envs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_from_mem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_envs_to_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_eval_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mload_from_mem\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/Documents/Study/CDM_torch_pddl/Curriculum_managers/repaired_curriculum.py\u001b[0m in \u001b[0;36mcreate_envs\u001b[0;34m(self, load_from_mem, number_of_envs, teacher_eval_mode)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0menv_params_anta\u001b[0m\u001b[0;34m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplr_anta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0menv_pro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstract_env\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0menv_pro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_from_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_params_pro\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstract_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_from_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_params_anta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0menv_anta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstract_env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/Documents/Study/CDM_torch_pddl/Environments/frozen.py\u001b[0m in \u001b[0;36minit_from_vec\u001b[0;34m(self, vec)\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;34m\"\"\"encoded number of loc\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mTypeError\u001b[0m: 'type' object is not iterable"
                    ]
                }
            ],
            "source": [
                "phf_rewards = phf_teacher.teach(n_iters=n_iters, n_episodes=1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# PAIRED History Filter Entropy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# phfe_agent = PPO_Agent(obs_shape, n_actions, device=device, batch_size=64, max_mem_size=10**5, lr=0.0001, model=rnn.RNN)\n",
                "# phfe_teacher_agent = PPO_Agent(gen_obs_shape, gen_action_dim, device=device, batch_size=64, max_mem_size=10**5, lr=0.0001, model=rnn.RNN)\n",
                "# phfe_teacher = PAIRED_Curriculum_History_filter_Entropy(env, teacher_agent=phfe_teacher_agent ,trainee=phfe_agent)\n",
                "# phfe_rewards = phfe_teacher.teach(n_iters=n_iters, n_episodes=1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# CLIMB"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "no files to load from\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "R:000000.0, entropy: 1.38: 100%|██████████| 200/200 [02:52<00:00,  1.16it/s] \n"
                    ]
                }
            ],
            "source": [
                "phfe_or_agent = PPO_Agent(obs_shape, n_actions, device=device, batch_size=64, max_mem_size=10**5, lr=0.0001, model=rnn.RNN)\n",
                "phfe_or_teacher_agent = PPO_Agent(gen_obs_shape, gen_action_dim, device=device, batch_size=64, max_mem_size=10**5, lr=0.0001, model=rnn.RNN)\n",
                "phfe_or_teacher = CLIMB(env, teacher_agent=phfe_or_teacher_agent ,trainee=phfe_or_agent)\n",
                "phfe_rewards = phfe_or_teacher.teach(n_iters=200, n_episodes=1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# UNREGULATED ENTROPY HISTORY"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "loading metadatafrom ./results/Curriculum_Unregulated_Entropy_History/FrozenLakeEnv/meta_data.pkl\n",
                        "loading models from last iter: 199\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "R:000000.0, entropy: 1.382: 100%|██████████| 51/51 [00:05<00:00,  8.84it/s]\n"
                    ]
                }
            ],
            "source": [
                "pee_agent = PPO_Agent(obs_shape, n_actions, device=device, batch_size=64, max_mem_size=10**5, lr=0.0001, model=rnn.RNN)\n",
                "pee_teacher_agent = PPO_Agent(gen_obs_shape, gen_action_dim, device=device, batch_size=64, max_mem_size=10**5 ,lr=0.0001, model=rnn.RNN)\n",
                "pee_teacher = Curriculum_Unregulated_Entropy_History(env, teacher_agent=pee_teacher_agent ,trainee=pee_agent, inv_reward_entropy_coeff=1)\n",
                "pee_rewards = pee_teacher.teach(n_iters=250, n_episodes=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "env = pee_teacher.create_envs(1)[0]\n",
                "plt.imshow(env.render('rgb_array'))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# RESULTS CHECK"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "env.reset_random()\n",
                "plt.imshow(env.render('rgb_array'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 144,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['Cluttered1MinigridMini',\n",
                            " 'Cluttered6MinigridMini',\n",
                            " 'Cluttered7MinigridMini',\n",
                            " 'EmptyRandomEnv6x6Minigrid',\n",
                            " 'EmptyRandomEnv15x15Minigrid',\n",
                            " 'MiniTwoRoomsEnvMinigrid']"
                        ]
                    },
                    "execution_count": 144,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "domain_name = \"Maze\"\n",
                "difficulty = \"easy\"\n",
                "get_all_avail_test_envs(domain_name, difficulty)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 159,
            "metadata": {},
            "outputs": [],
            "source": [
                "env_name = \"EmptyRandomEnv6x6Minigrid\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 160,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<matplotlib.image.AxesImage at 0x7f67a8281880>"
                        ]
                    },
                    "execution_count": 160,
                    "metadata": {},
                    "output_type": "execute_result"
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "env = test_envs[domain_name][difficulty][env_name]()\n",
                "plt.imshow(env.render('rgb_array'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#pen_agent, p_agent, r_agent, pee_agent"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 86,
            "metadata": {},
            "outputs": [],
            "source": [
                "generic_agent = PPO_Agent(obs_shape, n_actions, device=device, batch_size=64, max_mem_size=10**5, lr=0.0001, model=rnn.RNN)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 161,
            "metadata": {},
            "outputs": [],
            "source": [
                "generic_agent.load_agent(\"./results/PAIRED_Curriculum/MiniAdversarialEnv/_49999_trainee.ckpt\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 162,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "evaluation episode: 0 R: 0 72\n"
                    ]
                }
            ],
            "source": [
                "env = test_envs[domain_name][difficulty][env_name]()\n",
                "agent = generic_agent\n",
                "agent.set_eval_mode()\n",
                "vid = []\n",
                "for i in range(1):\n",
                "    obs = env.reset()\n",
                "    # break\n",
                "    R = 0\n",
                "    t = 0\n",
                "    while True:\n",
                "        # Uncomment to watch the behavior in a GUI window\n",
                "        clear_output(wait=True)\n",
                "        frame = env.render('rgb_array')\n",
                "        # vid.append(frame)\n",
                "        plt.imshow(frame)\n",
                "        plt.show()\n",
                "        # env.render(mode='rgb_array')\n",
                "        # env.render()\n",
                "        action = agent.act(obs)\n",
                "        obs, r, done, _ = env.step(action)\n",
                "        # print(action, r, done)\n",
                "\n",
                "        R += r\n",
                "        t += 1\n",
                "        reset = t == 500\n",
                "        time.sleep(0.01)\n",
                "\n",
                "        if done or reset:\n",
                "            break\n",
                "print('evaluation episode:', i, 'R:', R, t)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "save_vid(vid,'test')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "def save_vid(frames, vid_name):\n",
                "    out = cv2.VideoWriter(vid_name+'.avi',cv2.VideoWriter_fourcc(*'DIVX'), 15, (800,640))\n",
                " \n",
                "    for i in range(len(frames)):\n",
                "        frame = cv2.cvtColor(frames[i], cv2.COLOR_RGB2BGR)\n",
                "        frame = cv2.resize(frame, (800,640))\n",
                "        out.write(frame)\n",
                "    out.release()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Curriculum results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_agent(agent, env, num_iters=1, plot=False):\n",
                "    agent.set_eval_mode()\n",
                "    mean_r = 0\n",
                "    for i in range(num_iters):\n",
                "        obs = env.reset()\n",
                "        # break\n",
                "        R = 0\n",
                "        t = 0\n",
                "        while True:\n",
                "            # Uncomment to watch the behavior in a GUI window\n",
                "            if plot:\n",
                "                clear_output(wait=True)\n",
                "                plt.imshow(env.render('rgb_array'))\n",
                "                plt.show()\n",
                "                time.sleep(0.01)\n",
                "\n",
                "            # env.render(mode='rgb_array')\n",
                "            # env.render()\n",
                "            action = agent.act(obs)\n",
                "            obs, r, done, _ = env.step(action)\n",
                "\n",
                "            R += r\n",
                "            t += 1\n",
                "            reset = t == 500\n",
                "\n",
                "            if done or reset:\n",
                "                break\n",
                "        mean_r +=R\n",
                "    return mean_r / num_iters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "runable_envs = {}\n",
                "for env_name in get_all_avail_test_envs():\n",
                "    try:\n",
                "        test_env = test_envs[env_name]()\n",
                "        runable_envs[env_name] = test_env\n",
                "    except:\n",
                "        print(\"Exception\",env_name, test_env.minigrid_mode)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "agents = {\"paired_entropy\": pen_agent, \"paired\":p_agent, \"random\":r_agent, \"entropy_only\":pee_agent, \"entropy_history\": peh_agent, \"paired_entropy_history\": penh_agent}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calc_result(agents, runable_envs):\n",
                "    i=0\n",
                "    all_results = np.zeros((len(runable_envs), len(agents)))\n",
                "    for env_name,env in runable_envs.items():\n",
                "        print(env_name, i, len(runable_envs))\n",
                "        j= 0\n",
                "        for a_name, a in agents.items():\n",
                "            env.__init__()\n",
                "            res = run_agent(a, env)\n",
                "            all_results[i][j] = res\n",
                "            j+=1\n",
                "        i+=1\n",
                "    return all_results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "agents = {\"random\":agent}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "all_results = calc_result(agents, runable_envs)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "clean_env_names = np.array(list(runable_envs.keys()))[~np.all(all_results == 0, axis=1)]\n",
                "clean_res = all_results[~np.all(all_results == 0, axis=1)]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_test_res_all(clean_res, clean_env_names, agents)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print_mean_score(all_results, agents)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def print_mean_score(all_results, agents):\n",
                "    scores = np.mean(all_results, axis=0)\n",
                "    for i,a in enumerate(agents):\n",
                "        print(f\"{a}_mean:\", scores[i])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from plotly.subplots import make_subplots\n",
                "from plotly import graph_objects as go\n",
                "def plot_test_res_all(data_array, env_names, agents_dict):\n",
                "    color10_16 = ['violet', 'orange', 'cyan', \"green\",  \"yellow\"]\n",
                "    col_len = int(np.sqrt(len(env_names)))\n",
                "    row_len = (col_len + len(env_names) - col_len**2)\n",
                "    fig = make_subplots(rows=row_len, cols=col_len, subplot_titles=env_names)\n",
                "    for i,env_name in enumerate(env_names):\n",
                "        fig.add_trace(\n",
                "            go.Bar(\n",
                "                name=env_name,\n",
                "                x=list(agents_dict.keys()),\n",
                "                y=data_array[i],\n",
                "                marker_color=color10_16\n",
                "            ),\n",
                "            row=(i // col_len) +1 ,\n",
                "            col =(i % col_len)+1,\n",
                "            \n",
                "        )\n",
                "    fig.update_layout(height=1600, width=1600, title_text=\"Reward Comparation\", showlegend=False, legend=dict(\n",
                "    yanchor=\"bottom\",\n",
                "    y=-0.5,\n",
                "    xanchor=\"right\",\n",
                "    x=1\n",
                "))\n",
                "    fig.show()"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "51d94fb03c43753a2426587823d2be8041f6a4754994b937dd91979af2d3883e"
        },
        "kernelspec": {
            "display_name": "Python 3.9.8 64-bit ('venv': venv)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.13"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
