{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "%matplotlib inline\n",
                "from IPython.display import clear_output\n",
                "import time\n",
                "from Environments.environments import all_envs, get_all_avail_envs\n",
                "from Agents.dqn_agent import DQN_Agent\n",
                "from Agents.ppo_agent import PPO_Agent\n",
                "from Models import fc, rnn\n",
                "import matplotlib.pyplot as plt\n",
                "import torch\n",
                "import utils\n",
                "from Curriculum_managers.random_curriculum import Random_Curriculum\n",
                "from Curriculum_managers.paired_curriculum import PAIRED_Curriculum\n",
                "from Curriculum_managers.paired_curriculum_extented import  PAIRED_Curriculum_entropy\n",
                "from Curriculum_managers.paired_curriculum_extented_no_regret import  PAIRED_Curriculum_no_regret_entropy\n",
                "import plotly.express as px\n",
                "import gym\n",
                "import os\n",
                "# os.environ[\"LANG\"]=\"en_US\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['SingleTaxiEnv',\n",
                            " 'FrozenLakeEnv',\n",
                            " 'AdversarialEnv',\n",
                            " 'ReparameterizedAdversarialEnv',\n",
                            " 'MiniAdversarialEnv',\n",
                            " 'MiniReparameterizedAdversarialEnv',\n",
                            " 'NoisyAdversarialEnv',\n",
                            " 'MediumAdversarialEnv',\n",
                            " 'GoalLastAdversarialEnv',\n",
                            " 'MiniGoalLastAdversarialEnv']"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "env_names = get_all_avail_envs()\n",
                "env_names"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "device = utils.init_torch()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "env = all_envs['MiniAdversarialEnv'](random_reset_loc=False)\n",
                "n_actions = env.action_space.n\n",
                "obs_shape = env.observation_space.shape\n",
                "gen_obs_shape = env.get_generator_observation_space().shape\n",
                "gen_action_dim = env.get_generator_action_space().n\n",
                "# gen_obs_shape = env.get_generator_observation_space()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "# env = gym.envs.make(\"CartPole-v1\")\n",
                "# n_actions = env.action_space.n\n",
                "# obs_shape = env.observation_space.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Random curriculum train single example:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "# agent = PPO(obs_shape, n_actions, device=device, batch_size=64, max_mem_size=10**5, exploration_epsilon=0.3, eps_dec=0, lr=0.001, model=rnn.RNN)\n",
                "# teacher_agent = DQN_Agent(gen_obs_shape, n_actions, device=device, batch_size=64, max_mem_size=10**5, exploration_epsilon=0.3, eps_dec=0, lr=0.001, model=rnn.RNN)\n",
                "\n",
                "r_agent = PPO_Agent(obs_shape, n_actions, device=device, batch_size=512, max_mem_size=10**5, lr=0.0001, model=rnn.RNN)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "r_teacher = Random_Curriculum(env, trainee=r_agent)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "R:000000.0:   5%|â–Œ         | 260/5000 [04:03<1:21:26,  1.03s/it]"
                    ]
                }
            ],
            "source": [
                "r_rewards = r_teacher.teach(n_iters=5000, n_episodes=8)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# PAIRED CURRICULUM"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "p_agent = PPO_Agent(obs_shape, n_actions, device=device, batch_size=512, max_mem_size=10**5, lr=0.0001, model=rnn.RNN)\n",
                "teacher_agent = PPO_Agent(gen_obs_shape, gen_action_dim, device=device, batch_size=512, max_mem_size=10**5, lr=0.0001, model=rnn.RNN)\n",
                "p_teacher = PAIRED_Curriculum(env, teacher_agent=teacher_agent ,trainee=p_agent)\n",
                "p_rewards = p_teacher.teach(n_iters=5000, n_episodes=8)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# fig = px.line(x=range(len(p_rewards)), y=p_rewards, title='Train rewards')\n",
                "# fig.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# PARIED_ENTROPY"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/5000 [00:00<?, ?it/s]\n"
                    ]
                },
                {
                    "ename": "TypeError",
                    "evalue": "'NoneType' object is not subscriptable",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m/tmp/ipykernel_339174/4271754486.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mteacher_agent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPPO_Agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_obs_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_action_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_mem_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mp_teacher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPAIRED_Curriculum_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mteacher_agent\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtrainee\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp_agent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mp_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_teacher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;32m~/Documents/Study/CDM_torch/Curriculum_managers/paired_curriculum_extented.py\u001b[0m in \u001b[0;36mteach\u001b[0;34m(self, n_iters, n_episodes)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0menvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_envs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_envs_to_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_eval_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/Documents/Study/CDM_torch/Curriculum_managers/paired_curriculum_extented.py\u001b[0m in \u001b[0;36mget_best_env\u001b[0;34m(self, env_list)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mall_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_states_to_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0ms_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m                 \u001b[0mall_obs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/Documents/Study/CDM_torch/Environments/adversarial.py\u001b[0m in \u001b[0;36msample_random_state\u001b[0;34m(self, seed)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0ma_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplace_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
                    ]
                }
            ],
            "source": [
                "p_agent = PPO_Agent(obs_shape, n_actions, device=device, batch_size=512, max_mem_size=10**5, lr=0.0001, model=rnn.RNN)\n",
                "teacher_agent = PPO_Agent(gen_obs_shape, gen_action_dim, device=device, batch_size=512, max_mem_size=10**5, lr=0.0001, model=rnn.RNN)\n",
                "p_teacher = PAIRED_Curriculum_entropy(env, teacher_agent=teacher_agent ,trainee=p_agent)\n",
                "p_rewards = p_teacher.teach(n_iters=5000, n_episodes=8)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# PARIED_ENTROPY_NO_REGRET"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/5000 [00:00<?, ?it/s]\n"
                    ]
                },
                {
                    "ename": "TypeError",
                    "evalue": "'NoneType' object is not subscriptable",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m/tmp/ipykernel_339174/4252492279.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mteacher_agent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPPO_Agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_obs_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_action_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_mem_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mp_teacher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPAIRED_Curriculum_no_regret_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mteacher_agent\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtrainee\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp_agent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mp_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_teacher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;32m~/Documents/Study/CDM_torch/Curriculum_managers/paired_curriculum_extented_no_regret.py\u001b[0m in \u001b[0;36mteach\u001b[0;34m(self, n_iters, n_episodes)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0menvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_envs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_envs_to_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_eval_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/Documents/Study/CDM_torch/Curriculum_managers/paired_curriculum_extented_no_regret.py\u001b[0m in \u001b[0;36mget_best_env\u001b[0;34m(self, env_list)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mall_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_states_to_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0ms_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m                 \u001b[0mall_obs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/Documents/Study/CDM_torch/Environments/adversarial.py\u001b[0m in \u001b[0;36msample_random_state\u001b[0;34m(self, seed)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0ma_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplace_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
                    ]
                }
            ],
            "source": [
                "p_agent = PPO_Agent(obs_shape, n_actions, device=device, batch_size=512, max_mem_size=10**5, lr=0.0001, model=rnn.RNN)\n",
                "teacher_agent = PPO_Agent(gen_obs_shape, gen_action_dim, device=device, batch_size=512, max_mem_size=10**5, lr=0.0001, model=rnn.RNN)\n",
                "p_teacher = PAIRED_Curriculum_no_regret_entropy(env, teacher_agent=teacher_agent ,trainee=p_agent)\n",
                "p_rewards = p_teacher.teach(n_iters=5000, n_episodes=8)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# RESULTS CHECK"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 54,
            "metadata": {},
            "outputs": [],
            "source": [
                "agent = r_agent"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 60,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[4] 0 False\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[0;32m/tmp/ipykernel_234879/2534208199.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mreset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "agent.set_train_mode()\n",
                "for i in range(1):\n",
                "    obs = env.reset()\n",
                "    # break\n",
                "    R = 0\n",
                "    t = 0\n",
                "    while True:\n",
                "        # Uncomment to watch the behavior in a GUI window\n",
                "        clear_output(wait=True)\n",
                "        plt.imshow(env.render('rgb_array'))\n",
                "        plt.show()\n",
                "        # env.render(mode='rgb_array')\n",
                "        # env.render()\n",
                "        action = agent.act(obs)\n",
                "        obs, r, done, _ = env.step(action)\n",
                "        print(action, r, done)\n",
                "\n",
                "        R += r\n",
                "        t += 1\n",
                "        reset = t == 500\n",
                "        time.sleep(0.5)\n",
                "        if done or reset:\n",
                "            break\n",
                "    print('evaluation episode:', i, 'R:', R)"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "6939f772228930f094315145e416d5954b20b1f6473e0de1ef78293fcab749f1"
        },
        "kernelspec": {
            "display_name": "Python 3.9.7 64-bit ('venv': venv)",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.9"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
